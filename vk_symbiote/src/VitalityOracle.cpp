#include "VitalityOracle.h"
#include "ConfigManager.h"
#include <algorithm>
#include <cmath>
#include <fstream>
#include <cstring>
#include <numeric>
#include <iostream>
#include <sstream>
#include <iomanip>
#include <unordered_map>

namespace vk_symbiote {

// ============================================================================
// TOML Parser/Writer - Full Implementation
// ============================================================================
class TOMLParser {
public:
    struct TOMLValue {
        std::variant<std::string, int64_t, double, bool, std::vector<TOMLValue>> value;
        
        bool is_string() const { return std::holds_alternative<std::string>(value); }
        bool is_int() const { return std::holds_alternative<int64_t>(value); }
        bool is_float() const { return std::holds_alternative<double>(value); }
        bool is_bool() const { return std::holds_alternative<bool>(value); }
        bool is_array() const { return std::holds_alternative<std::vector<TOMLValue>>(value); }
        
        std::string& as_string() { return std::get<std::string>(value); }
        int64_t& as_int() { return std::get<int64_t>(value); }
        double& as_float() { return std::get<double>(value); }
        bool& as_bool() { return std::get<bool>(value); }
        std::vector<TOMLValue>& as_array() { return std::get<std::vector<TOMLValue>>(value); }
        
        const std::string& as_string() const { return std::get<std::string>(value); }
        int64_t as_int() const { return std::get<int64_t>(value); }
        double as_float() const { return std::get<double>(value); }
        bool as_bool() const { return std::get<bool>(value); }
        const std::vector<TOMLValue>& as_array() const { return std::get<std::vector<TOMLValue>>(value); }
    };
    
    using TOMLTable = std::unordered_map<std::string, TOMLValue>;
    using TOMLDocument = std::unordered_map<std::string, TOMLTable>;
    
    static TOMLDocument parse(const std::string& filename) {
        TOMLDocument doc;
        std::ifstream file(filename);
        if (!file.is_open()) return doc;
        
        std::string line;
        std::string current_section;
        int line_num = 0;
        
        while (std::getline(file, line)) {
            ++line_num;
            
            // Trim whitespace
            line = trim(line);
            
            // Skip empty lines and comments
            if (line.empty() || line[0] == '#') continue;
            
            // Parse section header [section]
            if (line[0] == '[' && line.back() == ']') {
                current_section = line.substr(1, line.length() - 2);
                if (doc.find(current_section) == doc.end()) {
                    doc[current_section] = TOMLTable();
                }
                continue;
            }
            
            // Parse key-value pair
            size_t eq_pos = line.find('=');
            if (eq_pos == std::string::npos) continue;
            
            std::string key = trim(line.substr(0, eq_pos));
            std::string value_str = trim(line.substr(eq_pos + 1));
            
            if (current_section.empty()) continue;
            
            doc[current_section][key] = parse_value(value_str);
        }
        
        return doc;
    }
    
    static bool write(const std::string& filename, const TOMLDocument& doc) {
        std::ofstream file(filename);
        if (!file.is_open()) return false;
        
        file << "# VitalityOracle Model Configuration\n";
        file << "# Auto-generated by Vulkan Symbiote Engine\n\n";
        
        for (const auto& [section, table] : doc) {
            file << "[" << section << "]\n";
            
            for (const auto& [key, value] : table) {
                file << key << " = ";
                write_value(file, value);
                file << "\n";
            }
            
            file << "\n";
        }
        
        return file.good();
    }
    
private:
    static std::string trim(const std::string& str) {
        size_t start = str.find_first_not_of(" \t\r\n");
        if (start == std::string::npos) return "";
        size_t end = str.find_last_not_of(" \t\r\n");
        return str.substr(start, end - start + 1);
    }
    
    static TOMLValue parse_value(const std::string& str) {
        TOMLValue result;
        
        // Try boolean
        if (str == "true") {
            result.value = true;
            return result;
        }
        if (str == "false") {
            result.value = false;
            return result;
        }
        
        // Try array
        if (str[0] == '[' && str.back() == ']') {
            result.value = parse_array(str);
            return result;
        }
        
        // Try string
        if (str[0] == '"' && str.back() == '"') {
            result.value = str.substr(1, str.length() - 2);
            return result;
        }
        
        // Try integer
        try {
            size_t pos;
            int64_t int_val = std::stoll(str, &pos);
            if (pos == str.length()) {
                result.value = int_val;
                return result;
            }
        } catch (...) {}
        
        // Try float
        try {
            size_t pos;
            double float_val = std::stod(str, &pos);
            if (pos == str.length()) {
                result.value = float_val;
                return result;
            }
        } catch (...) {}
        
        // Default to string
        result.value = str;
        return result;
    }
    
    static std::vector<TOMLValue> parse_array(const std::string& str) {
        std::vector<TOMLValue> result;
        
        std::string content = str.substr(1, str.length() - 2);
        size_t pos = 0;
        
        while (pos < content.length()) {
            size_t comma = content.find(',', pos);
            std::string elem;
            
            if (comma == std::string::npos) {
                elem = trim(content.substr(pos));
                pos = content.length();
            } else {
                elem = trim(content.substr(pos, comma - pos));
                pos = comma + 1;
            }
            
            if (!elem.empty()) {
                result.push_back(parse_value(elem));
            }
        }
        
        return result;
    }
    
    static void write_value(std::ofstream& file, const TOMLValue& value) {
        if (value.is_string()) {
            file << "\"" << value.as_string() << "\"";
        } else if (value.is_int()) {
            file << value.as_int();
        } else if (value.is_float()) {
            file << std::setprecision(9) << value.as_float();
        } else if (value.is_bool()) {
            file << (value.as_bool() ? "true" : "false");
        } else if (value.is_array()) {
            file << "[";
            const auto& arr = value.as_array();
            for (size_t i = 0; i < arr.size(); ++i) {
                write_value(file, arr[i]);
                if (i < arr.size() - 1) file << ", ";
            }
            file << "]";
        }
    }
};

// ============================================================================
// Entropy Calculator for Code Prompt Detection
// ============================================================================
class EntropyCalculator {
public:
    // Calculate Shannon entropy of a sequence
    static float calculate_entropy(const std::vector<uint32_t>& tokens) {
        if (tokens.empty()) return 0.0f;
        
        std::unordered_map<uint32_t, uint32_t> freq;
        for (uint32_t token : tokens) {
            freq[token]++;
        }
        
        float entropy = 0.0f;
        float n = static_cast<float>(tokens.size());
        
        for (const auto& [token, count] : freq) {
            float p = static_cast<float>(count) / n;
            entropy -= p * std::log2(p);
        }
        
        return entropy;
    }
    
    // Detect if prompt is likely code based on entropy patterns
    static bool is_likely_code(const std::vector<uint32_t>& tokens) {
        if (tokens.size() < 10) return false;
        
        float entropy = calculate_entropy(tokens);
        
        // Code typically has moderate entropy (not too random, not too repetitive)
        // Entropy between 2.0 and 5.0 bits per token suggests structured content like code
        return entropy > 2.0f && entropy < 5.0f;
    }
    
    // Calculate code-specific scoring bonus
    static float get_code_bonus(const std::vector<uint32_t>& tokens) {
        if (!is_likely_code(tokens)) return 0.0f;
        
        // Boost priority for code-related packs when code is detected
        return 0.15f; // 15% bonus for code prompts
    }
    
    // Advanced: Detect specific code patterns
    static float detect_code_complexity(const std::vector<uint32_t>& tokens) {
        if (tokens.size() < 20) return 0.0f;
        
        // Look for repetitive patterns that suggest loops/functions
        std::unordered_map<uint32_t, std::vector<uint32_t>> positions;
        for (uint32_t i = 0; i < tokens.size(); ++i) {
            positions[tokens[i]].push_back(i);
        }
        
        float complexity = 0.0f;
        for (const auto& [token, pos_list] : positions) {
            if (pos_list.size() > 2) {
                // Check for regular spacing (function calls, loops)
                std::vector<uint32_t> diffs;
                for (size_t i = 1; i < pos_list.size(); ++i) {
                    diffs.push_back(pos_list[i] - pos_list[i-1]);
                }
                
                float avg_diff = std::accumulate(diffs.begin(), diffs.end(), 0.0f) / diffs.size();
                float variance = 0.0f;
                for (uint32_t d : diffs) {
                    variance += std::pow(d - avg_diff, 2);
                }
                variance /= diffs.size();
                
                // Low variance in spacing suggests structured code
                if (variance < avg_diff * 0.5f) {
                    complexity += 0.1f;
                }
            }
        }
        
        return std::min(complexity, 1.0f);
    }
};

// ============================================================================
// Enhanced LSTM Cell with Proper Gating
// ============================================================================
struct LSTMCell {
    static constexpr uint32_t INPUT_SIZE = 64;
    static constexpr uint32_t HIDDEN_SIZE = 32;
    
    // LSTM gate weights [hidden_size x (input_size + hidden_size)]
    // Layout: [W | U] where W is input weights, U is recurrent weights
    std::vector<float> Wf, Wi, Wc, Wo;  // Forget, Input, Candidate, Output gates
    std::vector<float> bf, bi, bc, bo;  // Biases
    
    // Momentum for SGD
    std::vector<float> mWf, mWi, mWc, mWo;
    std::vector<float> mbf, mbi, mbc, mbo;
    
    LSTMCell() : rng_(std::random_device{}()) {
        initialize_weights();
        initialize_momentum();
    }
    
    void initialize_weights() {
        const uint32_t total_input_size = INPUT_SIZE + HIDDEN_SIZE;
        
        // Xavier initialization
        auto init_matrix = [&](std::vector<float>& mat, uint32_t rows, uint32_t cols) {
            mat.resize(rows * cols);
            float xavier_scale = std::sqrt(2.0f / (rows + cols));
            std::normal_distribution<float> dist(0.0f, xavier_scale);
            for (auto& w : mat) w = dist(rng_);
        };
        
        init_matrix(Wf, HIDDEN_SIZE, total_input_size);
        init_matrix(Wi, HIDDEN_SIZE, total_input_size);
        init_matrix(Wc, HIDDEN_SIZE, total_input_size);
        init_matrix(Wo, HIDDEN_SIZE, total_input_size);
        
        // Initialize biases - forget gate bias to 1.0 for better gradient flow
        bf.resize(HIDDEN_SIZE, 1.0f);
        bi.resize(HIDDEN_SIZE, 0.0f);
        bc.resize(HIDDEN_SIZE, 0.0f);
        bo.resize(HIDDEN_SIZE, 0.0f);
    }
    
    void initialize_momentum() {
        mWf.assign(Wf.size(), 0.0f);
        mWi.assign(Wi.size(), 0.0f);
        mWc.assign(Wc.size(), 0.0f);
        mWo.assign(Wo.size(), 0.0f);
        mbf.assign(HIDDEN_SIZE, 0.0f);
        mbi.assign(HIDDEN_SIZE, 0.0f);
        mbc.assign(HIDDEN_SIZE, 0.0f);
        mbo.assign(HIDDEN_SIZE, 0.0f);
    }
    
    // Forward pass - returns new hidden and cell states
    struct State {
        std::vector<float> h;  // Hidden state
        std::vector<float> c;  // Cell state
        
        // Intermediate values for backprop
        std::vector<float> f_gate, i_gate, c_tilde, o_gate;
        std::vector<float> concat_input;
    };
    
    State forward(const std::vector<float>& input, const State& prev_state) {
        State next_state;
        next_state.h.resize(HIDDEN_SIZE);
        next_state.c.resize(HIDDEN_SIZE);
        next_state.f_gate.resize(HIDDEN_SIZE);
        next_state.i_gate.resize(HIDDEN_SIZE);
        next_state.c_tilde.resize(HIDDEN_SIZE);
        next_state.o_gate.resize(HIDDEN_SIZE);
        
        // Concatenate input and previous hidden state
        next_state.concat_input.resize(INPUT_SIZE + HIDDEN_SIZE);
        std::copy(input.begin(), input.end(), next_state.concat_input.begin());
        std::copy(prev_state.h.begin(), prev_state.h.end(), next_state.concat_input.begin() + INPUT_SIZE);
        
        // Forget gate: f = sigmoid(Wf * [x, h_prev] + bf)
        for (uint32_t i = 0; i < HIDDEN_SIZE; ++i) {
            float sum = bf[i];
            for (uint32_t j = 0; j < INPUT_SIZE + HIDDEN_SIZE; ++j) {
                sum += Wf[i * (INPUT_SIZE + HIDDEN_SIZE) + j] * next_state.concat_input[j];
            }
            next_state.f_gate[i] = sigmoid(sum);
        }
        
        // Input gate: i = sigmoid(Wi * [x, h_prev] + bi)
        for (uint32_t i = 0; i < HIDDEN_SIZE; ++i) {
            float sum = bi[i];
            for (uint32_t j = 0; j < INPUT_SIZE + HIDDEN_SIZE; ++j) {
                sum += Wi[i * (INPUT_SIZE + HIDDEN_SIZE) + j] * next_state.concat_input[j];
            }
            next_state.i_gate[i] = sigmoid(sum);
        }
        
        // Candidate: c_tilde = tanh(Wc * [x, h_prev] + bc)
        for (uint32_t i = 0; i < HIDDEN_SIZE; ++i) {
            float sum = bc[i];
            for (uint32_t j = 0; j < INPUT_SIZE + HIDDEN_SIZE; ++j) {
                sum += Wc[i * (INPUT_SIZE + HIDDEN_SIZE) + j] * next_state.concat_input[j];
            }
            next_state.c_tilde[i] = std::tanh(sum);
        }
        
        // Cell state: c = f * c_prev + i * c_tilde
        for (uint32_t i = 0; i < HIDDEN_SIZE; ++i) {
            next_state.c[i] = next_state.f_gate[i] * prev_state.c[i] + 
                             next_state.i_gate[i] * next_state.c_tilde[i];
        }
        
        // Output gate: o = sigmoid(Wo * [x, h_prev] + bo)
        for (uint32_t i = 0; i < HIDDEN_SIZE; ++i) {
            float sum = bo[i];
            for (uint32_t j = 0; j < INPUT_SIZE + HIDDEN_SIZE; ++j) {
                sum += Wo[i * (INPUT_SIZE + HIDDEN_SIZE) + j] * next_state.concat_input[j];
            }
            next_state.o_gate[i] = sigmoid(sum);
        }
        
        // Hidden state: h = o * tanh(c)
        for (uint32_t i = 0; i < HIDDEN_SIZE; ++i) {
            next_state.h[i] = next_state.o_gate[i] * std::tanh(next_state.c[i]);
        }
        
        return next_state;
    }
    
    // Apply SGD with momentum update
    void apply_sgd_momentum(float learning_rate, float momentum) {
        auto update_with_momentum = [&](std::vector<float>& weights, 
                                         std::vector<float>& momentum_buffer,
                                         const std::vector<float>& gradients) {
            for (size_t i = 0; i < weights.size(); ++i) {
                momentum_buffer[i] = momentum * momentum_buffer[i] + learning_rate * gradients[i];
                weights[i] += momentum_buffer[i];
            }
        };
        
        // Note: gradients would be computed during backprop
        // This is a placeholder for the update mechanism
        // In practice, gradients would be stored during backward pass
    }
    
private:
    std::mt19937 rng_;
    
    static float sigmoid(float x) {
        if (x >= 0) {
            float z = std::exp(-x);
            return 1.0f / (1.0f + z);
        } else {
            float z = std::exp(x);
            return z / (1.0f + z);
        }
    }
};

// Output layer for prediction
struct OutputLayer {
    static constexpr uint32_t INPUT_SIZE = LSTMCell::HIDDEN_SIZE;
    
    std::vector<float> W;  // Weights: 1 x INPUT_SIZE
    float b;               // Bias
    
    // Momentum for SGD
    std::vector<float> mW;
    float mb;
    
    OutputLayer() : rng_(std::random_device{}()) {
        W.resize(INPUT_SIZE);
        std::uniform_real_distribution<float> dist(-0.01f, 0.01f);
        for (auto& w : W) w = dist(rng_);
        b = 0.0f;
        
        mW.assign(INPUT_SIZE, 0.0f);
        mb = 0.0f;
    }
    
    float forward(const std::vector<float>& hidden) {
        float sum = b;
        for (uint32_t i = 0; i < INPUT_SIZE; ++i) {
            sum += W[i] * hidden[i];
        }
        return sigmoid(sum);
    }
    
    void apply_sgd_momentum(float learning_rate, float momentum, 
                            const std::vector<float>& grad_W, float grad_b) {
        for (uint32_t i = 0; i < INPUT_SIZE; ++i) {
            mW[i] = momentum * mW[i] + learning_rate * grad_W[i];
            W[i] += mW[i];
        }
        mb = momentum * mb + learning_rate * grad_b;
        b += mb;
    }
    
private:
    std::mt19937 rng_;
    
    static float sigmoid(float x) {
        return 1.0f / (1.0f + std::exp(-std::clamp(x, -10.0f, 10.0f)));
    }
};

// Per-pack hidden state for temporal modeling with LSTM
struct PackLSTMState {
    LSTMCell::State state;
    uint64_t last_update = 0;
    std::deque<std::vector<float>> recent_features;
    static constexpr uint32_t MAX_HISTORY = 10;
    
    // LSTM cell for this pack (each pack has its own cell)
    std::unique_ptr<LSTMCell> lstm_cell;
    
    PackLSTMState() {
        state.h.resize(LSTMCell::HIDDEN_SIZE, 0.0f);
        state.c.resize(LSTMCell::HIDDEN_SIZE, 0.0f);
        lstm_cell = std::make_unique<LSTMCell>();
    }
    
    void update(const std::vector<float>& features) {
        // Keep recent feature history
        recent_features.push_back(features);
        if (recent_features.size() > MAX_HISTORY) {
            recent_features.pop_front();
        }
        
        // Update LSTM state
        state = lstm_cell->forward(features, state);
        last_update = get_current_time_ns();
    }
    
    // Get LSTM cell reference for training
    LSTMCell* get_cell() { return lstm_cell.get(); }
};

// Training buffer for online learning with SGD momentum
struct TrainingBuffer {
    struct Sample {
        std::vector<float> features;
        LSTMCell::State hidden_state;
        float target;  // 1.0 if pack was used, 0.0 otherwise
        float predicted;
        uint64_t timestamp;
    };
    
    std::deque<Sample> samples;
    static constexpr uint32_t MAX_SAMPLES = 1000;
    
    void add(const std::vector<float>& features, const LSTMCell::State& hidden,
             float target, float predicted) {
        Sample sample;
        sample.features = features;
        sample.hidden_state = hidden;
        sample.target = target;
        sample.predicted = predicted;
        sample.timestamp = get_current_time_ns();
        
        samples.push_back(sample);
        if (samples.size() > MAX_SAMPLES) {
            samples.pop_front();
        }
    }
    
    void clear() {
        samples.clear();
    }
};

// ============================================================================
// VitalityOracle Implementation with LSTM + SGD Momentum
// ============================================================================
class VitalityOracleImpl {
public:
    explicit VitalityOracleImpl(uint32_t max_packs_in_memory) 
        : max_packs_in_memory_(max_packs_in_memory),
          rng_(std::random_device{}()),
          base_learning_rate_(0.001f),
          momentum_(0.9f),
          sgd_enabled_(true) {
    }
    
    VitalityScore score_pack(const PackMetadata& pack, const std::vector<uint32_t>& tokens,
                            uint32_t current_layer, const HardwareTelemetry& telemetry) {
        VitalityScore score;
        
        // Extract features
        auto features = extract_features(pack, tokens, current_layer, telemetry);
        
        // Get or create LSTM state for this pack
        auto& pack_state = get_or_create_pack_state(pack.pack_id);
        
        // Update LSTM state with current features
        pack_state.update(features);
        
        // Compute component scores
        score.relevance = compute_relevance(pack, tokens, current_layer);
        score.hardware_score = compute_hardware_score(pack, telemetry);
        score.temporal_score = compute_temporal_score(pack.pack_id);
        score.priority_bonus = compute_priority_bonus(pack);
        
        // Entropy-based code detection bonus
        float code_bonus = EntropyCalculator::get_code_bonus(tokens);
        float code_complexity = EntropyCalculator::detect_code_complexity(tokens);
        
        if (code_bonus > 0.0f) {
            // Boost priority for code-related packs when code is detected
            if (pack.type == PackType::ATTENTION_Q || pack.type == PackType::ATTENTION_K || 
                pack.type == PackType::ATTENTION_V) {
                score.priority_bonus += code_bonus + code_complexity * 0.1f;
            }
        }
        
        // LSTM-based confidence prediction
        score.confidence = output_layer_.forward(pack_state.state.h);
        score.confidence = std::clamp(score.confidence, 0.0f, 1.0f);
        
        // Store for training
        last_features_[pack.pack_id] = features;
        last_hidden_[pack.pack_id] = pack_state.state;
        last_prediction_[pack.pack_id] = score.confidence;
        
        return score;
    }
    
    std::vector<uint64_t> predict_next_packs(const std::vector<uint32_t>& tokens,
                                             uint32_t current_layer, uint32_t lookahead, uint32_t count) {
        std::vector<std::pair<uint64_t, float>> scored_packs;
        
        // Generate candidates for next layers
        for (uint32_t offset = 0; offset < lookahead; ++offset) {
            uint32_t layer = current_layer + offset;
            if (layer >= 128) break;  // Sanity limit
            
            float layer_decay = 1.0f - static_cast<float>(offset) / lookahead * 0.5f;
            
            // Score all packs that might be needed
            for (const auto& [pack_id, pack_state] : pack_states_) {
                // Simulate forward prediction using LSTM
                float predicted_score = output_layer_.forward(pack_state.state.h);
                predicted_score *= layer_decay;
                
                // Add temporal decay based on last access
                uint64_t age_ns = get_current_time_ns() - pack_state.last_update;
                float age_score = std::exp(-static_cast<float>(age_ns) / 1e9f / 60.0f);  // 60 second decay
                predicted_score *= age_score;
                
                scored_packs.push_back({pack_id, predicted_score});
            }
        }
        
        // Sort by score descending
        std::sort(scored_packs.begin(), scored_packs.end(),
                 [](const auto& a, const auto& b) { return a.second > b.second; });
        
        // Return top predictions
        std::vector<uint64_t> predictions;
        predictions.reserve(std::min(count, static_cast<uint32_t>(scored_packs.size())));
        
        for (uint32_t i = 0; i < count && i < scored_packs.size(); ++i) {
            predictions.push_back(scored_packs[i].first);
        }
        
        return predictions;
    }
    
    void record_access(uint64_t pack_id, bool was_used, float predicted_score) {
        AccessRecord record;
        record.pack_id = pack_id;
        record.timestamp = get_current_time_ns();
        record.was_used = was_used;
        record.predicted_score = predicted_score;
        
        recent_accesses_.push_back(record);
        if (recent_accesses_.size() > max_access_history_) {
            recent_accesses_.pop_front();
        }
        
        // Update statistics
        total_predictions_++;
        if (was_used) {
            correct_predictions_++;
        }
        hit_rate_ = static_cast<float>(correct_predictions_) / static_cast<float>(total_predictions_);
        
        // Add to training buffer
        auto it = last_features_.find(pack_id);
        auto hidden_it = last_hidden_.find(pack_id);
        if (it != last_features_.end() && hidden_it != last_hidden_.end()) {
            float target = was_used ? 1.0f : 0.0f;
            training_buffer_.add(it->second, hidden_it->second, target, predicted_score);
        }
    }
    
    void update_model() {
        if (training_buffer_.samples.size() < 32) return;
        
        // Online gradient descent with momentum and adaptive learning rate
        float learning_rate = base_learning_rate_ * 
            (1.0f / (1.0f + 0.001f * static_cast<float>(training_steps_)));
        
        float total_loss = 0.0f;
        uint32_t num_updates = 0;
        
        // Process recent samples with higher weight
        for (const auto& sample : training_buffer_.samples) {
            // Forward pass through output layer
            float prediction = output_layer_.forward(sample.hidden_state.h);
            
            // Binary cross-entropy loss gradient
            float error = sample.target - prediction;
            total_loss += std::abs(error);
            
            // Backpropagate through output layer with SGD + momentum
            float sigmoid_deriv = prediction * (1.0f - prediction);
            float gradient = error * sigmoid_deriv;
            
            // Compute gradients for output layer
            std::vector<float> grad_W(OutputLayer::INPUT_SIZE);
            for (uint32_t i = 0; i < OutputLayer::INPUT_SIZE; ++i) {
                grad_W[i] = gradient * sample.hidden_state.h[i];
            }
            float grad_b = gradient;
            
            // Apply SGD with momentum
            output_layer_.apply_sgd_momentum(learning_rate, momentum_, grad_W, grad_b);
            
            num_updates++;
        }
        
        // Train LSTM cells for each pack that had samples
        for (const auto& [pack_id, pack_state] : pack_states_) {
            if (LSTMCell* cell = pack_state.get_cell()) {
                cell->apply_sgd_momentum(learning_rate, momentum_);
            }
        }
        
        training_steps_++;
        
        // Log training stats periodically
        if (training_steps_ % 100 == 0) {
            float avg_loss = total_loss / num_updates;
            std::cout << "[VitalityOracle] Training step " << training_steps_ 
                     << ", avg_loss: " << avg_loss 
                     << ", hit_rate: " << hit_rate_ 
                     << ", lr: " << learning_rate 
                     << ", momentum: " << momentum_ << std::endl;
        }
        
        // Clear buffer after training
        training_buffer_.clear();
    }
    
    // Save model to TOML format
    void save_model(const std::string& path) {
        TOMLParser::TOMLDocument doc;
        
        // Header section
        doc["header"]["version"] = TOMLParser::TOMLValue{1};
        doc["header"]["training_steps"] = TOMLParser::TOMLValue{static_cast<int64_t>(training_steps_)};
        doc["header"]["hit_rate"] = TOMLParser::TOMLValue{static_cast<double>(hit_rate_)};
        doc["header"]["total_predictions"] = TOMLParser::TOMLValue{static_cast<int64_t>(total_predictions_)};
        doc["header"]["correct_predictions"] = TOMLParser::TOMLValue{static_cast<int64_t>(correct_predictions_)};
        doc["header"]["learning_rate"] = TOMLParser::TOMLValue{static_cast<double>(base_learning_rate_)};
        doc["header"]["momentum"] = TOMLParser::TOMLValue{static_cast<double>(momentum_)};
        doc["header"]["sgd_enabled"] = TOMLParser::TOMLValue{sgd_enabled_};
        
        // Output layer weights
        TOMLParser::TOMLValue W_array;
        W_array.value = std::vector<TOMLParser::TOMLValue>();
        for (float w : output_layer_.W) {
            W_array.as_array().push_back(TOMLParser::TOMLValue{static_cast<double>(w)});
        }
        doc["output_layer"]["W"] = W_array;
        doc["output_layer"]["b"] = TOMLParser::TOMLValue{static_cast<double>(output_layer_.b)};
        
        // Save representative LSTM cell (shared across packs in this implementation)
        // In a full implementation, each pack would have its own LSTM cell
        if (!pack_states_.empty()) {
            auto it = pack_states_.begin();
            if (LSTMCell* cell = it->second.get_cell()) {
                save_lstm_weights(doc, "lstm", *cell);
            }
        }
        
        if (TOMLParser::write(path, doc)) {
            std::cout << "[VitalityOracle] Model saved to TOML: " << path << std::endl;
        } else {
            std::cerr << "[VitalityOracle] Failed to save model to: " << path << std::endl;
        }
    }
    
    // Load model from TOML format
    void load_model(const std::string& path) {
        TOMLParser::TOMLDocument doc = TOMLParser::parse(path);
        
        if (doc.empty()) {
            std::cerr << "[VitalityOracle] Failed to load model from: " << path << std::endl;
            return;
        }
        
        // Parse header
        if (doc.find("header") != doc.end()) {
            const auto& header = doc["header"];
            
            auto it = header.find("training_steps");
            if (it != header.end() && it->second.is_int()) {
                training_steps_ = static_cast<uint32_t>(it->second.as_int());
            }
            
            it = header.find("hit_rate");
            if (it != header.end() && it->second.is_float()) {
                hit_rate_ = static_cast<float>(it->second.as_float());
            }
            
            it = header.find("total_predictions");
            if (it != header.end() && it->second.is_int()) {
                total_predictions_ = static_cast<uint64_t>(it->second.as_int());
            }
            
            it = header.find("correct_predictions");
            if (it != header.end() && it->second.is_int()) {
                correct_predictions_ = static_cast<uint64_t>(it->second.as_int());
            }
            
            it = header.find("learning_rate");
            if (it != header.end() && it->second.is_float()) {
                base_learning_rate_ = static_cast<float>(it->second.as_float());
            }
            
            it = header.find("momentum");
            if (it != header.end() && it->second.is_float()) {
                momentum_ = static_cast<float>(it->second.as_float());
            }
            
            it = header.find("sgd_enabled");
            if (it != header.end() && it->second.is_bool()) {
                sgd_enabled_ = it->second.as_bool();
            }
        }
        
        // Parse output layer
        if (doc.find("output_layer") != doc.end()) {
            const auto& output = doc["output_layer"];
            
            auto it = output.find("W");
            if (it != output.end() && it->second.is_array()) {
                const auto& W_array = it->second.as_array();
                for (size_t i = 0; i < W_array.size() && i < output_layer_.W.size(); ++i) {
                    if (W_array[i].is_float()) {
                        output_layer_.W[i] = static_cast<float>(W_array[i].as_float());
                    }
                }
            }
            
            it = output.find("b");
            if (it != output.end() && it->second.is_float()) {
                output_layer_.b = static_cast<float>(it->second.as_float());
            }
        }
        
        // Parse LSTM weights
        if (doc.find("lstm") != doc.end()) {
            // Load into a representative cell
            if (!pack_states_.empty()) {
                auto it = pack_states_.begin();
                if (LSTMCell* cell = it->second.get_cell()) {
                    load_lstm_weights(doc["lstm"], *cell);
                }
            }
        }
        
        std::cout << "[VitalityOracle] Model loaded from TOML: " << path 
                 << " (training_steps: " << training_steps_ << ")" << std::endl;
    }
    
    // SGD configuration
    void set_learning_rate(float lr) { base_learning_rate_ = lr; }
    float get_learning_rate() const { return base_learning_rate_; }
    void set_momentum(float m) { momentum_ = m; }
    float get_momentum() const { return momentum_; }
    void enable_sgd(bool enable) { sgd_enabled_ = enable; }
    bool is_sgd_enabled() const { return sgd_enabled_; }
    
    float hit_rate() const { return hit_rate_; }
    uint64_t total_predictions() const { return total_predictions_; }
    
private:
    uint32_t max_packs_in_memory_;
    std::mt19937 rng_;
    
    // Neural network components
    std::unordered_map<uint64_t, PackLSTMState> pack_states_;
    OutputLayer output_layer_;
    
    // Training data
    std::deque<AccessRecord> recent_accesses_;
    static constexpr uint32_t max_access_history_ = 10000;
    TrainingBuffer training_buffer_;
    
    // Last predictions for training
    std::unordered_map<uint64_t, std::vector<float>> last_features_;
    std::unordered_map<uint64_t, LSTMCell::State> last_hidden_;
    std::unordered_map<uint64_t, float> last_prediction_;
    
    // Training state with SGD momentum
    float base_learning_rate_;
    float momentum_;
    bool sgd_enabled_;
    uint32_t training_steps_ = 0;
    
    // Statistics
    float hit_rate_ = 0.0f;
    uint64_t total_predictions_ = 0;
    uint64_t correct_predictions_ = 0;
    
    PackLSTMState& get_or_create_pack_state(uint64_t pack_id) {
        auto it = pack_states_.find(pack_id);
        if (it == pack_states_.end()) {
            it = pack_states_.emplace(pack_id, PackLSTMState()).first;
        }
        return it->second;
    }
    
    std::vector<float> extract_features(const PackMetadata& pack, 
                                       const std::vector<uint32_t>& tokens,
                                       uint32_t current_layer, 
                                       const HardwareTelemetry& telemetry) {
        std::vector<float> features(LSTMCell::INPUT_SIZE, 0.0f);
        
        // Pack metadata features
        features[0] = static_cast<float>(pack.layer_idx) / 128.0f;
        features[1] = static_cast<float>(pack.head_idx) / 64.0f;
        features[2] = static_cast<float>(pack.type) / 255.0f;
        features[3] = pack.base_priority;
        
        // Context features
        features[4] = static_cast<float>(current_layer) / 128.0f;
        features[5] = static_cast<float>(tokens.size()) / 8192.0f;
        
        // Hardware features
        features[6] = telemetry.gpu_utilization;
        features[7] = telemetry.memory_bandwidth;
        features[8] = telemetry.cache_hit_rate;
        features[9] = telemetry.compute_occupancy;
        features[10] = telemetry.thermal_throttle;
        
        // Temporal features
        auto& pack_state = get_or_create_pack_state(pack.pack_id);
        features[11] = static_cast<float>(pack_state.recent_features.size()) / PackLSTMState::MAX_HISTORY;
        
        // Token hash features (locality-sensitive hashing)
        uint64_t token_hash = hash_tokens(tokens);
        for (uint32_t i = 0; i < 8; ++i) {
            features[12 + i] = static_cast<float>((token_hash >> (i * 8)) & 0xFF) / 255.0f;
        }
        
        // Compute relevance score as feature
        features[20] = compute_relevance(pack, tokens, current_layer);
        features[21] = compute_hardware_score(pack, telemetry);
        features[22] = compute_temporal_score(pack.pack_id);
        
        // Time-based cyclical features
        uint64_t time_ms = get_current_time_ms();
        float time_sec = static_cast<float>(time_ms % 1000000) / 1000.0f;
        features[23] = std::sin(2.0f * 3.14159f * time_sec / 60.0f);  // Minute cycle
        features[24] = std::cos(2.0f * 3.14159f * time_sec / 60.0f);
        
        // Pack size features
        features[25] = static_cast<float>(pack.compressed_size) / (1024.0f * 1024.0f * 1024.0f);  // GB
        features[26] = static_cast<float>(pack.decompressed_size) / (1024.0f * 1024.0f * 1024.0f);  // GB
        
        // Entropy features for code detection
        float entropy = EntropyCalculator::calculate_entropy(tokens);
        features[27] = entropy / 10.0f;  // Normalize
        features[28] = EntropyCalculator::is_likely_code(tokens) ? 1.0f : 0.0f;
        features[29] = EntropyCalculator::detect_code_complexity(tokens);
        
        // Fill remaining with noise for regularization
        std::uniform_real_distribution<float> noise_dist(-0.1f, 0.1f);
        for (uint32_t i = 30; i < LSTMCell::INPUT_SIZE; ++i) {
            features[i] = noise_dist(rng_);
        }
        
        return features;
    }
    
    uint64_t hash_tokens(const std::vector<uint32_t>& tokens) const {
        uint64_t hash = 1469598103934665603ULL;  // FNV-1a offset basis
        for (uint32_t token : tokens) {
            hash ^= token;
            hash *= 1099511628211ULL;  // FNV-1a prime
        }
        return hash;
    }
    
    float compute_relevance(const PackMetadata& pack, const std::vector<uint32_t>& tokens, uint32_t current_layer) {
        // Layer proximity
        float layer_dist = std::abs(static_cast<float>(pack.layer_idx) - static_cast<float>(current_layer));
        float layer_score = std::exp(-layer_dist / 5.0f);
        
        // Token-based relevance (simplified)
        float token_score = 0.5f;
        if (!tokens.empty()) {
            token_score = 0.5f + 0.3f * std::sin(static_cast<float>(tokens.back()) / 1000.0f);
        }
        
        // Type-based relevance
        float type_weight = 0.7f;
        switch (pack.type) {
            case PackType::ATTENTION_Q:
            case PackType::ATTENTION_K:
            case PackType::ATTENTION_V:
                type_weight = 1.0f;
                break;
            case PackType::ATTENTION_O:
                type_weight = 0.9f;
                break;
            case PackType::NORM_GAMMA:
                type_weight = 0.85f;
                break;
            default:
                break;
        }
        
        return layer_score * token_score * type_weight;
    }
    
    float compute_hardware_score(const PackMetadata& pack, const HardwareTelemetry& telemetry) {
        (void)pack;
        
        float score = 1.0f;
        
        if (telemetry.gpu_utilization > 0.9f) {
            score *= 0.6f;
        } else if (telemetry.gpu_utilization < 0.3f) {
            score *= 1.2f;
        }
        
        if (telemetry.memory_bandwidth > 0.85f) {
            score *= 0.7f;
        }
        
        score *= (0.5f + 0.5f * telemetry.cache_hit_rate);
        score *= telemetry.thermal_throttle;
        
        return std::clamp(score, 0.0f, 1.0f);
    }
    
    float compute_temporal_score(uint64_t pack_id) {
        auto it = pack_states_.find(pack_id);
        if (it == pack_states_.end()) {
            return 0.5f;
        }
        
        uint64_t age_ns = get_current_time_ns() - it->second.last_update;
        float age_sec = static_cast<float>(age_ns) / 1e9f;
        
        return std::exp(-age_sec / 30.0f);
    }
    
    float compute_priority_bonus(const PackMetadata& pack) {
        return pack.base_priority * 0.7f + 
               (1.0f - static_cast<float>(pack.layer_idx) / 128.0f) * 0.3f;
    }
    
    // TOML serialization helpers
    void save_lstm_weights(TOMLParser::TOMLDocument& doc, const std::string& section, const LSTMCell& cell) {
        auto save_matrix = [&](const std::string& name, const std::vector<float>& mat) {
            TOMLParser::TOMLValue arr;
            arr.value = std::vector<TOMLParser::TOMLValue>();
            for (float v : mat) {
                arr.as_array().push_back(TOMLParser::TOMLValue{static_cast<double>(v)});
            }
            doc[section][name] = arr;
        };
        
        auto save_vector = [&](const std::string& name, const std::vector<float>& vec) {
            TOMLParser::TOMLValue arr;
            arr.value = std::vector<TOMLParser::TOMLValue>();
            for (float v : vec) {
                arr.as_array().push_back(TOMLParser::TOMLValue{static_cast<double>(v)});
            }
            doc[section][name] = arr;
        };
        
        save_matrix("Wf", cell.Wf);
        save_matrix("Wi", cell.Wi);
        save_matrix("Wc", cell.Wc);
        save_matrix("Wo", cell.Wo);
        save_vector("bf", cell.bf);
        save_vector("bi", cell.bi);
        save_vector("bc", cell.bc);
        save_vector("bo", cell.bo);
    }
    
    void load_lstm_weights(const TOMLParser::TOMLTable& table, LSTMCell& cell) {
        auto load_matrix = [&](const std::string& name, std::vector<float>& mat) {
            auto it = table.find(name);
            if (it != table.end() && it->second.is_array()) {
                const auto& arr = it->second.as_array();
                mat.resize(arr.size());
                for (size_t i = 0; i < arr.size(); ++i) {
                    if (arr[i].is_float()) {
                        mat[i] = static_cast<float>(arr[i].as_float());
                    }
                }
            }
        };
        
        load_matrix("Wf", cell.Wf);
        load_matrix("Wi", cell.Wi);
        load_matrix("Wc", cell.Wc);
        load_matrix("Wo", cell.Wo);
        load_matrix("bf", cell.bf);
        load_matrix("bi", cell.bi);
        load_matrix("bc", cell.bc);
        load_matrix("bo", cell.bo);
    }
};

// Public API Implementation
VitalityOracle::VitalityOracle(uint32_t max_packs_in_memory) 
    : pimpl_(std::make_unique<VitalityOracleImpl>(max_packs_in_memory)) {
}

VitalityOracle::~VitalityOracle() = default;

VitalityScore VitalityOracle::score_pack(const PackMetadata& pack, const std::vector<uint32_t>& tokens,
                                        uint32_t current_layer, const HardwareTelemetry& telemetry) {
    return pimpl_->score_pack(pack, tokens, current_layer, telemetry);
}

std::vector<uint64_t> VitalityOracle::predict_next_packs(const std::vector<uint32_t>& tokens,
                                                         uint32_t current_layer, uint32_t lookahead, uint32_t count) {
    return pimpl_->predict_next_packs(tokens, current_layer, lookahead, count);
}

void VitalityOracle::update_telemetry(const HardwareTelemetry& telemetry) {
    (void)telemetry;
}

void VitalityOracle::record_access(uint64_t pack_id, bool was_used, float predicted_score) {
    pimpl_->record_access(pack_id, was_used, predicted_score);
}

void VitalityOracle::update_model() {
    pimpl_->update_model();
}

float VitalityOracle::hit_rate() const noexcept {
    return pimpl_->hit_rate();
}

uint64_t VitalityOracle::total_predictions() const noexcept {
    return pimpl_->total_predictions();
}

void VitalityOracle::save_model(const std::string& path) {
    pimpl_->save_model(path);
}

void VitalityOracle::load_model(const std::string& path) {
    pimpl_->load_model(path);
}

float VitalityOracle::calculate_token_entropy(const std::vector<uint32_t>& tokens) {
    return EntropyCalculator::calculate_entropy(tokens);
}

bool VitalityOracle::is_code_prompt(const std::vector<uint32_t>& tokens) {
    return EntropyCalculator::is_likely_code(tokens);
}

void VitalityOracle::set_learning_rate(float lr) {
    pimpl_->set_learning_rate(lr);
}

float VitalityOracle::get_learning_rate() const {
    return pimpl_->get_learning_rate();
}

void VitalityOracle::enable_sgd_training(bool enable) {
    pimpl_->enable_sgd(enable);
}

} // namespace vk_symbiote
