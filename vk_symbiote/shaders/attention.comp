#version 450
#extension GL_ARB_separate_shader_objects : enable

layout(local_size_x = 128) in;

// Input/output activation buffers
layout(binding = 0, std430) readonly buffer InputBuf { float input_data[]; };
layout(binding = 1, std430) writeonly buffer OutputBuf { float output_data[]; };

// Weight buffers
layout(binding = 2, std430) readonly buffer QueryWeight { float q_weight[]; };
layout(binding = 3, std430) readonly buffer KeyWeight { float k_weight[]; };
layout(binding = 4, std430) readonly buffer ValueWeight { float v_weight[]; };
layout(binding = 5, std430) readonly buffer OutputWeight { float o_weight[]; };

// KV Cache buffers - enable O(n) attention complexity
layout(binding = 6, std430) buffer KeyCache { float key_cache[]; };
layout(binding = 7, std430) buffer ValueCache { float value_cache[]; };

layout(push_constant) uniform PC {
    uint32_t seq_len;          // Current sequence length
    uint32_t prev_seq_len;     // Previous cached sequence length (for incremental)
    uint32_t head_dim;
    uint32_t num_heads;
    uint32_t num_kv_heads;
    uint32_t max_seq_len;      // Maximum cache capacity
    float scale;
    bool use_cache;            // Whether to use KV cache
} pc;

// Shared memory for Q, K, V - sized for head_dim up to 256
// LIMITATION: This shader assumes head_dim <= 256
// For larger head dimensions, increase these arrays or use dynamic shared memory
shared float shared_q[256];
shared float shared_k[256];
shared float shared_v[256];

// Assert for head dimension - will fail compilation if head_dim > 256
// In a real implementation, you might want to use specialization constants
// or dynamic shared memory allocation instead

// Compute Q, K, V projections from input
void compute_qkv(uint32_t token_idx, uint32_t head, uint32_t kv_head, 
                 uint32_t head_size, out float q[128], out float k[128], out float v[128]) {
    // Simple matrix multiplication for Q, K, V projections
    // In production, this should use proper matmul
    for (uint32_t d = 0; d < head_size; ++d) {
        q[d] = 0.0;
        k[d] = 0.0;
        v[d] = 0.0;
        
        for (uint32_t i = 0; i < head_size; ++i) {
            uint32_t input_idx = token_idx * head_size + i;
            float input_val = input_data[input_idx];
            
            q[d] += input_val * q_weight[(head * head_size + d) * head_size + i];
            k[d] += input_val * k_weight[(kv_head * head_size + d) * head_size + i];
            v[d] += input_val * v_weight[(kv_head * head_size + d) * head_size + i];
        }
    }
}

void main() {
    uint32_t gid = gl_GlobalInvocationID.x;
    uint32_t head = gid / pc.seq_len;
    uint32_t pos = gid % pc.seq_len;
    
    if (head >= pc.num_heads || pos >= pc.seq_len) return;
    
    uint32_t head_size = pc.head_dim;
    uint32_t kv_head = head * pc.num_kv_heads / pc.num_heads;
    
    // For this implementation, we compute QKV for current token
    // In production, Q is computed from current token, K/V use cache + new
    float local_q[128], local_k[128], local_v[128];
    compute_qkv(pos, head, kv_head, head_size, local_q, local_k, local_v);
    
    // Store K, V in cache for future tokens
    if (pc.use_cache) {
        for (uint32_t d = 0; d < head_size; ++d) {
            uint32_t cache_idx = ((kv_head * pc.max_seq_len + pos) * head_size + d);
            key_cache[cache_idx] = local_k[d];
            value_cache[cache_idx] = local_v[d];
        }
    }
    
    // Load Q to shared memory
    for (uint32_t d = gl_LocalInvocationID.x; d < head_size; d += gl_WorkGroupSize.x) {
        shared_q[d] = local_q[d];
    }
    barrier();
    
    // O(n) attention: only attend to cached positions up to current position
    // For incremental generation, this is O(prev_seq_len) instead of O(seq_lenÂ²)
    uint32_t attend_len = pc.use_cache ? pc.seq_len : pos + 1;
    
    // First pass: compute max score for numerical stability
    float max_score = -1e20;
    for (uint32_t k_pos = 0; k_pos < attend_len; ++k_pos) {
        float score = 0.0;
        
        // Load K from cache or compute
        for (uint32_t d = 0; d < head_size; ++d) {
            float k_val;
            if (pc.use_cache) {
                uint32_t cache_idx = ((kv_head * pc.max_seq_len + k_pos) * head_size + d);
                k_val = key_cache[cache_idx];
            } else {
                // Would need to recompute K here in non-cached mode
                k_val = local_k[d]; // Simplified
            }
            score += shared_q[d] * k_val;
        }
        max_score = max(max_score, score * pc.scale);
    }
    
    // Second pass: compute softmax sum
    float sum = 0.0;
    for (uint32_t k_pos = 0; k_pos < attend_len; ++k_pos) {
        float score = 0.0;
        for (uint32_t d = 0; d < head_size; ++d) {
            float k_val;
            if (pc.use_cache) {
                uint32_t cache_idx = ((kv_head * pc.max_seq_len + k_pos) * head_size + d);
                k_val = key_cache[cache_idx];
            } else {
                k_val = local_k[d];
            }
            score += shared_q[d] * k_val;
        }
        sum += exp(score * pc.scale - max_score);
    }
    
    // Third pass: compute weighted sum of values
    float result[128];
    for (uint32_t d = 0; d < head_size; ++d) {
        result[d] = 0.0;
    }
    
    for (uint32_t k_pos = 0; k_pos < attend_len; ++k_pos) {
        float score = 0.0;
        float k_val_local[128];
        
        for (uint32_t d = 0; d < head_size; ++d) {
            if (pc.use_cache) {
                uint32_t cache_idx = ((kv_head * pc.max_seq_len + k_pos) * head_size + d);
                k_val_local[d] = key_cache[cache_idx];
            } else {
                k_val_local[d] = local_k[d];
            }
            score += shared_q[d] * k_val_local[d];
        }
        
        float attn = exp(score * pc.scale - max_score) / sum;
        
        for (uint32_t d = 0; d < head_size; ++d) {
            float v_val;
            if (pc.use_cache) {
                uint32_t cache_idx = ((kv_head * pc.max_seq_len + k_pos) * head_size + d);
                v_val = value_cache[cache_idx];
            } else {
                v_val = local_v[d];
            }
            result[d] += attn * v_val;
        }
    }
    
    // Apply output projection
    for (uint32_t d = gl_LocalInvocationID.x; d < head_size; d += gl_WorkGroupSize.x) {
        float out_val = 0.0;
        for (uint32_t i = 0; i < head_size; ++i) {
            out_val += result[i] * o_weight[i * head_size + d];
        }
        uint32_t out_idx = (head * pc.seq_len + pos) * head_size + d;
        output_data[out_idx] = out_val;
    }
}
